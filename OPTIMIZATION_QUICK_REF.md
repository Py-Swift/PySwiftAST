# Quick Reference: Performance Optimization

## ğŸš€ Quick Start

```bash
# 1. Establish baseline
swift test -c release --filter PerformanceTests 2>&1 | tee current_run.txt
python3 scripts/check_performance.py current_run.txt

# 2. Check grammar for the feature you're optimizing
grep -A 10 "your_rule" Grammar/python.gram

# 3. Make ONE optimization change
# ... edit code ...

# 4. Test correctness
swift test

# 5. Test performance
swift test -c release --filter PerformanceTests 2>&1 | python3 scripts/check_performance.py

# 6. If improved, update history and commit
# If regressed, REVERT immediately
```

## âœ… Pre-Optimization Checklist

- [ ] Run baseline performance tests
- [ ] Check Grammar/python.gram for correctness
- [ ] Profile to identify actual hotspot
- [ ] Plan ONE specific optimization

## ğŸ”„ Optimization Loop

```
1. Baseline â†’ 2. Grammar Check â†’ 3. Profile â†’ 
4. Optimize ONE thing â†’ 5. Test ALL â†’ 6. Measure â†’ 
7. Compare â†’ Decision:
   âœ… Improved? â†’ Update history + Commit â†’ Loop
   â¡ï¸ Neutral?  â†’ Review code quality â†’ Decide
   âŒ Regressed? â†’ REVERT â†’ Try different approach
```

## ğŸ“Š Key Metrics to Track

- **Parsing median** (primary): Currently 6.4ms, Goal: 4.3ms (2x vs Python)
- **Round-trip median**: Currently 29.6ms, Goal: 20.2ms (1.5x vs Python)
- **Test pass rate**: Must be 100% (all 80+ tests)

## ğŸš« Never Do This

- âŒ Optimize without profiling
- âŒ Change multiple things at once
- âŒ Skip grammar verification
- âŒ Accept regressions
- âŒ Commit with failing tests

## âœ… Always Do This

- âœ… Measure before and after
- âœ… One optimization at a time
- âœ… Verify against Grammar/python.gram
- âœ… Run full test suite
- âœ… Update performance_history.json
- âœ… Document why the optimization works

## ğŸ“ Key Files

- `OPTIMIZATION_GUIDELINES.md` - Full detailed guidelines
- `performance_history.json` - Performance tracking database
- `Grammar/python.gram` - Python 3.13 grammar (source of truth)
- `Tests/PySwiftASTTests/PerformanceTests.swift` - Performance test suite
- `scripts/check_performance.py` - Performance comparison tool

## ğŸ¯ Current Goals

**Parsing**: 1.35x â†’ 2.0x faster than Python (need 32% improvement)
**Round-trip**: 1.04x â†’ 1.5x faster than Python (need 27% improvement)

## ğŸ“ Common Commands

```bash
# Profile with Instruments
instruments -t "Time Profiler" .build/release/pyswift-benchmark \
  Tests/PySwiftASTTests/Resources/test_files/django_query.py 100 parse

# Search grammar
grep -n "expression" Grammar/python.gram

# Run all tests
swift test

# Run performance tests
swift test -c release --filter PerformanceTests

# Compare performance
python3 scripts/check_performance.py <test_output.txt>

# View history
cat performance_history.json | python3 -m json.tool
```

## ğŸ† Success Pattern

```
âœ… Profile identified parseExpression as 30% of runtime
âœ… Checked grammar - implementation matches
âœ… Reduced bounds checking using unsafelyUnwrapped
âœ… All 80 tests pass
âœ… Performance: 6.4ms â†’ 6.1ms (4.7% improvement)
âœ… Updated history with details
âœ… Committed with clear message
```

## âš ï¸ Failure Pattern (Don't Do This)

```
âŒ "I think tokenization is slow" (no profiling)
âŒ Changed 5 things at once
âŒ Didn't check grammar
âŒ 2 tests failing, "will fix later"
âŒ Performance regressed 3%
âŒ Committed anyway
```

---

**Remember**: Measure, don't guess. One thing at a time. Never break correctness.
